"""
FastAPI Application for Phishing Detection API

This module provides a production-ready REST API for phishing detection with:
- CORS support for frontend integration
- Rate limiting for security
- Request logging for monitoring
- Global exception handling
- ML model loading on startup (not per request)

What is CORS?
-------------
CORS (Cross-Origin Resource Sharing) is a security mechanism that controls
which websites can access your API from a browser.

Example Problem:
- Your API runs on http://localhost:8000
- Your frontend runs on http://localhost:3000
- By default, browsers BLOCK requests from frontend to API (different origins)

Solution:
- Enable CORS middleware to allow specific origins (like localhost:3000)
- This tells browsers: "It's OK for localhost:3000 to access this API"

Why We Need It:
- Modern web apps have separate frontend and backend servers
- Browsers enforce Same-Origin Policy for security
- CORS allows controlled cross-origin access

Security Note:
- In production, only allow trusted domains (not '*')
- Our config allows localhost:3000 for development
"""

from fastapi import FastAPI, Request, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
import time
import logging
import uuid
from datetime import datetime
from typing import Dict, Optional
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent))

from api.models import (
    PredictionRequest, PredictionResponse,
    ExplainRequest, ExplainResponse,
    FeedbackRequest, FeedbackResponse,
    HealthResponse, ErrorResponse,
    VerdictEnum, ConfidenceEnum
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# RATE LIMITING
# ============================================================================

# Create rate limiter
# What is rate limiting?
# - Prevents abuse by limiting requests per user/IP
# - Example: 100 requests per minute per IP
# - Protects against DoS attacks and resource exhaustion
limiter = Limiter(key_func=get_remote_address)

# ============================================================================
# FASTAPI APP INITIALIZATION
# ============================================================================

app = FastAPI(
    title="Phishing Detection API",
    description="""
    Advanced Machine Learning API for detecting phishing emails.
    
    Features:
    - Text and URL feature analysis
    - Ensemble model predictions
    - SHAP-based explanations
    - High accuracy (>90%) phishing detection
    
    Input: email_text (string) - URLs are extracted automatically
    """,
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add rate limiting to app
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# ============================================================================
# CORS MIDDLEWARE
# ============================================================================

# Enable CORS for frontend integration
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # React/Next.js dev server
        "http://localhost:8080",  # Alternative frontend port
        "http://127.0.0.1:3000",  # Alternative localhost
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

logger.info("CORS enabled for localhost:3000")

# ============================================================================
# REQUEST LOGGING MIDDLEWARE
# ============================================================================

@app.middleware("http")
async def log_requests(request: Request, call_next):
    """
    Log all incoming requests with timing information.
    
    Purpose:
    - Monitor API usage
    - Debug issues
    - Track performance
    - Audit security events
    """
    start_time = time.time()
    
    # Log incoming request
    logger.info(f"Request: {request.method} {request.url.path} from {request.client.host}")
    
    # Process request
    response = await call_next(request)
    
    # Calculate processing time
    process_time = (time.time() - start_time) * 1000  # Convert to ms
    
    # Log response
    logger.info(
        f"Response: {request.method} {request.url.path} "
        f"Status={response.status_code} Time={process_time:.2f}ms"
    )
    
    # Add processing time to response headers
    response.headers["X-Process-Time"] = f"{process_time:.2f}ms"
    
    return response

# ============================================================================
# GLOBAL EXCEPTION HANDLERS
# ============================================================================

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """
    Handle Pydantic validation errors.
    
    Purpose:
    - Provide clear error messages for invalid input
    - Return user-friendly responses
    - Log validation failures
    """
    logger.warning(f"Validation error: {exc.errors()}")
    
    return JSONResponse(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        content={
            "error": "ValidationError",
            "message": "Invalid request data",
            "detail": exc.errors()
        }
    )


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """Handle HTTP exceptions."""
    logger.error(f"HTTP error: {exc.status_code} - {exc.detail}")
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": f"HTTPException",
            "message": exc.detail,
            "detail": None
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """
    Handle unexpected errors.
    
    Purpose:
    - Prevent server crashes
    - Log errors for debugging
    - Return safe error messages (don't expose internal details)
    """
    logger.error(f"Unexpected error: {str(exc)}", exc_info=True)
    
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "error": "InternalServerError",
            "message": "An unexpected error occurred",
            "detail": "Please contact support if this persists"
        }
    )

# ============================================================================
# MODEL LOADING ON STARTUP
# ============================================================================

# Global variables for ML models (loaded once on startup)
text_classifier = None
url_classifier = None
ensemble_model = None
explainer = None
models_loaded = False

@app.on_event("startup")
async def load_models():
    """
    Load ML models on application startup.
    
    Why load on startup?
    - Models are large (several MB)
    - Loading takes time (1-5 seconds)
    - Loading per request would be SLOW and wasteful
    - Load once, use many times (efficient)
    
    Note: In production, you might load from cloud storage or model registry
    """
    global text_classifier, url_classifier, ensemble_model, explainer, models_loaded
    
    logger.info("=" * 70)
    logger.info("LOADING ML MODELS")
    logger.info("=" * 70)
    
    try:
        # Use simple model loader for test models
        from utils.simple_model_loader import load_simple_models
        
        logger.info("Loading models...")
        text_classifier, url_classifier, ensemble_model = load_simple_models()
        
        # No explainer for now (optional)
        explainer = None
        
        models_loaded = True
        logger.info("[OK] All models loaded successfully")
        logger.info("=" * 70)
        
    except Exception as e:
        logger.error(f"[FAIL] Failed to load models: {str(e)}")
        models_loaded = False
        # Don't raise - allow API to start for testing


@app.on_event("shutdown")
async def shutdown_event():
    """Clean up resources on shutdown."""
    logger.info("Shutting down API...")

# ============================================================================
# HEALTH CHECK ENDPOINT
# ============================================================================

@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check():
    """
    Health check endpoint.
    
    Purpose:
    - Monitoring systems can check if API is alive
    - Load balancers can route traffic to healthy instances
    - Deployment pipelines can verify successful deployment
    
    Returns:
    --------
    HealthResponse with status, version, and model loading status
    """
    return HealthResponse(
        status="healthy",
        version="1.0.0",
        models_loaded=models_loaded
    )

# ============================================================================
# ROOT ENDPOINT
# ============================================================================

@app.get("/", tags=["Info"])
async def root():
    """
    Root endpoint with API information.
    
    Returns:
    --------
    API info including available endpoints and documentation links
    """
    return {
        "name": "Phishing Detection API",
        "version": "1.0.0",
        "description": "Machine Learning API for detecting phishing emails",
        "documentation": {
            "swagger": "/docs",
            "redoc": "/redoc"
        },
        "endpoints": {
            "predict": "/api/v1/predict",
            "explain": "/api/v1/explain",
            "feedback": "/api/v1/feedback",
            "health": "/health"
        },
        "status": "healthy" if models_loaded else "models_not_loaded",
        "input_format": "All endpoints accept email_text (string) - URLs extracted automatically"
    }

# ============================================================================
# API ENDPOINTS (Routers will be added here)
# ============================================================================

@app.post("/api/v1/predict", response_model=PredictionResponse, tags=["Prediction"])
@limiter.limit("100/minute")  # Rate limit: 100 requests per minute
async def predict(request: Request, data: PredictionRequest):
    """
    Predict if an email is phishing.
    
    Input:
    ------
    - email_text: Email content (URLs extracted automatically)
    
    Output:
    -------
    - risk_score: Phishing probability (0-1)
    - verdict: SAFE or PHISHING
    - confidence: LOW, MEDIUM, or HIGH
    - Individual model scores
    - Processing time
    
    Rate Limit: 100 requests/minute per IP
    """
    start_time = time.perf_counter()
    
    if not models_loaded:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Models not loaded yet. Please try again later."
        )
    
    try:
        # Generate unique prediction ID
        prediction_id = str(uuid.uuid4())
        
        # Get predictions from loaded models
        scores = ensemble_model.get_individual_scores([data.email_text])
        text_score = scores['text_score']
        url_score = scores['url_score']
        ensemble_score = scores['ensemble_score']
        
        # Determine verdict and confidence
        verdict = VerdictEnum.PHISHING if ensemble_score >= 0.5 else VerdictEnum.SAFE
        
        if ensemble_score >= 0.85 or ensemble_score <= 0.15:
            confidence = ConfidenceEnum.HIGH
        elif ensemble_score >= 0.65 or ensemble_score <= 0.35:
            confidence = ConfidenceEnum.MEDIUM
        else:
            confidence = ConfidenceEnum.LOW
        
        # Calculate processing time
        processing_time = (time.perf_counter() - start_time) * 1000  # ms
        
        return PredictionResponse(
            prediction_id=prediction_id,
            risk_score=ensemble_score,
            verdict=verdict,
            confidence=confidence,
            text_score=text_score,
            url_score=url_score,
            ensemble_score=ensemble_score,
            processing_time_ms=processing_time,
            model_version="1.0.0",
            timestamp=datetime.now()
        )
        
    except Exception as e:
        logger.error(f"Prediction error: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Prediction failed: {str(e)}"
        )


@app.post("/api/v1/explain", response_model=ExplainResponse, tags=["Explanation"])
@limiter.limit("100/minute")
async def explain(request: Request, data: ExplainRequest):
    """
    Explain why an email was classified as phishing or safe.
    
    Input:
    ------
    - email_text: Email content to explain
    
    Output:
    -------
    - risk_score: Phishing probability
    - verdict: SAFE or PHISHING
    - top_reasons: Human-readable explanations
    - trigger_words: Specific suspicious words
    - explanation_text: Detailed narrative
    
    Rate Limit: 100 requests/minute per IP
    """
    if not models_loaded:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Models not loaded yet. Please try again later."
        )
    
    try:
        # Get risk factors from explainer
        # risk_report = explainer.get_risk_factors(data.email_text)
        
        # Placeholder (replace with actual explanation)
        risk_report = {
            'risk_score': 0.87,
            'verdict': 'PHISHING',
            'top_reasons': [
                "Contains urgency words (verify, suspend, click)",
                "URL uses IP address instead of domain name",
                "Unusually high capital letter ratio (SHOUTING)"
            ]
        }
        
        # Extract trigger words (simplified)
        trigger_words = ["URGENT", "verify", "suspended", "click"]
        
        # Generate explanation text
        explanation_text = (
            f"This email is classified as {risk_report['verdict']} "
            f"with a risk score of {risk_report['risk_score']:.2%}. "
            f"The main indicators are: {', '.join(risk_report['top_reasons'][:2])}."
        )
        
        return ExplainResponse(
            risk_score=risk_report['risk_score'],
            verdict=VerdictEnum(risk_report['verdict']),
            top_reasons=risk_report['top_reasons'],
            trigger_words=trigger_words,
            explanation_text=explanation_text
        )
        
    except Exception as e:
        logger.error(f"Explanation error: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Explanation failed: {str(e)}"
        )


@app.post("/api/v1/feedback", response_model=FeedbackResponse, tags=["Feedback"])
@limiter.limit("100/minute")
async def submit_feedback(request: Request, data: FeedbackRequest):
    """
    Submit feedback on a prediction.
    
    Purpose:
    --------
    - Collect user corrections for model improvement
    - Track false positives/negatives
    - Enable continuous learning
    
    Input:
    ------
    - prediction_id: ID of the prediction
    - true_label: Correct label (user correction)
    - comment: Optional context
    
    Output:
    -------
    - Confirmation message
    - Feedback ID for tracking
    
    Rate Limit: 100 requests/minute per IP
    """
    try:
        # In production, save to database
        # For now, just log it
        logger.info(
            f"Feedback received: {data.prediction_id} â†’ {data.true_label} "
            f"({data.comment or 'no comment'})"
        )
        
        # Generate feedback ID
        feedback_id = f"fb_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # TODO: Save to database or feedback storage
        # db.save_feedback({
        #     'feedback_id': feedback_id,
        #     'prediction_id': data.prediction_id,
        #     'true_label': data.true_label,
        #     'comment': data.comment,
        #     'timestamp': datetime.now()
        # })
        
        return FeedbackResponse(
            message="Feedback received successfully. Thank you for helping improve our model!",
            feedback_id=feedback_id
        )
        
    except Exception as e:
        logger.error(f"Feedback submission error: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Feedback submission failed: {str(e)}"
        )


# ============================================================================
# RUN SERVER
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    logger.info("Starting Phishing Detection API...")
    logger.info("Documentation available at: http://localhost:8000/docs")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # Auto-reload on code changes (dev only)
        log_level="info"
    )
